{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf9ee45-9f7d-4a7b-ac17-7ee52870dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for Mage\n",
    "\n",
    "import io\n",
    "import requests\n",
    "import docx\n",
    "def clean_line(line):\n",
    "    line = line.strip()\n",
    "    line = line.strip('\\uFEFF')\n",
    "    return line\n",
    "\n",
    "def read_faq(file_id):\n",
    "    url = f'https://docs.google.com/document/d/{file_id}/export?format=docx'\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    with io.BytesIO(response.content) as f_in:\n",
    "        doc = docx.Document(f_in)\n",
    "\n",
    "    questions = []\n",
    "\n",
    "    question_heading_style = 'heading 2'\n",
    "    section_heading_style = 'heading 1'\n",
    "    \n",
    "    heading_id = ''\n",
    "    section_title = ''\n",
    "    question_title = ''\n",
    "    answer_text_so_far = ''\n",
    "     \n",
    "    for p in doc.paragraphs:\n",
    "        style = p.style.name.lower()\n",
    "        p_text = clean_line(p.text)\n",
    "    \n",
    "        if len(p_text) == 0:\n",
    "            continue\n",
    "    \n",
    "        if style == section_heading_style:\n",
    "            section_title = p_text\n",
    "            continue\n",
    "    \n",
    "        if style == question_heading_style:\n",
    "            answer_text_so_far = answer_text_so_far.strip()\n",
    "            if answer_text_so_far != '' and section_title != '' and question_title != '':\n",
    "                questions.append({\n",
    "                    'text': answer_text_so_far,\n",
    "                    'section': section_title,\n",
    "                    'question': question_title,\n",
    "                })\n",
    "                answer_text_so_far = ''\n",
    "    \n",
    "            question_title = p_text\n",
    "            continue\n",
    "        \n",
    "        answer_text_so_far += '\\n' + p_text\n",
    "    \n",
    "    answer_text_so_far = answer_text_so_far.strip()\n",
    "    if answer_text_so_far != '' and section_title != '' and question_title != '':\n",
    "        questions.append({\n",
    "            'text': answer_text_so_far,\n",
    "            'section': section_title,\n",
    "            'question': question_title,\n",
    "        })\n",
    "\n",
    "    return questions\n",
    "\n",
    "@data_loader\n",
    "def load_data(*args, **kwargs):\n",
    "    faq_documents = {\n",
    "    'llm-zoomcamp': '1T3MdwUvqCL3jrh3d3VCXQ8xE0UqRzI3bfgpfBq3ZWG0',\n",
    "    }\n",
    "    documents = []\n",
    "\n",
    "    for course, file_id in faq_documents.items():\n",
    "        print(course)\n",
    "        course_documents = read_faq(file_id)\n",
    "        documents.append({'course': course, 'documents': course_documents})\n",
    "    print(len(documents))\n",
    "    return documents\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d656805b-73b3-4182-86f1-3d4af1e8ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def generate_document_id(doc):\n",
    "    combined = f\"{doc['course']}-{doc['question']}-{doc['text'][:10]}\"\n",
    "    hash_object = hashlib.md5(combined.encode())\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "    document_id = hash_hex[:8]\n",
    "    return document_id\n",
    "\n",
    "@transformer\n",
    "def transform(data, *args, **kwargs):\n",
    "    print(type(data), len(data))\n",
    "    documents = []\n",
    "    if type(data) == list and len(data) == 1: data = data[0]\n",
    "    \n",
    "    \n",
    "\n",
    "    for doc in data['documents']:\n",
    "        doc['course'] = data['course']\n",
    "        # previously we used just \"id\" for document ID\n",
    "        doc['document_id'] = generate_document_id(doc)\n",
    "        documents.append(doc)\n",
    "\n",
    "    print(len(documents))\n",
    "\n",
    "    return documents\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cfe3f8-81cb-4bf3-b6f6-1ed574708d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def generate_document_id(doc):\n",
    "    combined = f\"{doc['course']}-{doc['question']}-{doc['text'][:10]}\"\n",
    "    hash_object = hashlib.md5(combined.encode())\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "    document_id = hash_hex[:8]\n",
    "    return document_id\n",
    "\n",
    "@transformer\n",
    "def transform(data, *args, **kwargs):\n",
    "    print(type(data), len(data))\n",
    "    documents = []\n",
    "    if type(data) == list and len(data) == 1: data = data[0]\n",
    "    \n",
    "    \n",
    "\n",
    "    for doc in data['documents']:\n",
    "        doc['course'] = data['course']\n",
    "        # previously we used just \"id\" for document ID\n",
    "        doc['document_id'] = generate_document_id(doc)\n",
    "        documents.append(doc)\n",
    "\n",
    "    print(len(documents))\n",
    "\n",
    "    return documents\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79509358-dbe9-489d-865e-832d41293fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Union\n",
    "\n",
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "\n",
    "\n",
    "@data_loader\n",
    "\n",
    "\n",
    "def search(*args, **kwargs):\n",
    "    connection_string = kwargs.get('connection_string', 'http://Elasticsearch:9200')\n",
    "    es_client = Elasticsearch(connection_string)\n",
    "    indices = es_client.indices.get_alias(index=\"*\")\n",
    "    print(indices)\n",
    "    #index_name = kwargs.get('index_name', 'documents_20240819_5838')\n",
    "    index_name = 'documents_20240819_3230'\n",
    "    query_text = \"When is the next cohort?\"\n",
    "    top_k = kwargs.get('top_k', 5)\n",
    "    response = es_client.search(\n",
    "            index=index_name,\n",
    "            body={\n",
    "            \"size\": 5,\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": query_text,\n",
    "                            \"fields\": [\"question\", \"text\"],\n",
    "                            \"type\": \"best_fields\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )    \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    print(response)\n",
    "    print([hit['_source']['document_id'] for hit in response['hits']['hits']]\n",
    ")\n",
    "    return [hit['_source']['document_id'] for hit in response['hits']['hits']]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
